le projet intitulé « Détection et classification des troubles du spectre autistique ». En ce qui concerne notre environnement technique, nous avons utilisé TensorFlow et Keras pour construire, former et évaluer notre modèle d'apprentissage. Dans ce contexte, nous avons adapté les fonctions de ces bibliothèques, telles que Sequential, fit et review.
Pour la visualisation des données, nous avons utilisé Matplotlib et Pandas. Nous avons combiné ces deux bibliothèques pour extraire directement les données des structures de données et les utiliser comme entrées pour créer des graphiques. Ces bibliothèques ont également été utilisées dans nos étapes d'évaluation de modèles.
Nous avons intégré OpenCV-Python dans notre projet de prétraitement d'images.
Notre projet est passé par plusieurs étapes, à commencer par :
Collecte de données : Notre collecte de données impliquait la collecte et l'organisation d'images à l'aide d'une base de données publique contenant un total de 2 490 images d'enfants étiquetés comme affectés ou non par les troubles du spectre autistique (TSA). Nous avons divisé les images en trois catégories dans trois répertoires différents : un pour la formation (2 540 images), un autre pour le réglage des hyperparamètres (validation) et un troisième contenant 300 images pour évaluer les performances du modèle après la formation.
Prétraitement des données : L'objectif de cette étape était de préparer les images pour l'entrée du modèle et de faciliter leur exploitation. Les images étant déjà de bonne qualité et équilibrées en termes d’intensité et de couleur, nous n’avons pas eu besoin de techniques telles que la réduction du bruit ou la normalisation. Nous avons redimensionné les images à l'aide de la fonction cv2.resize pour conserver une taille uniforme (150x150) pour toutes les images. Les étiquettes ont été extraites duimage names to associate each image with a class. We stored training images and their labels in lists and later converted them to NumPy arrays. The same procedures were applied to validation images.
Model Construction: We chose the VGG16 model for its deep architecture known for capturing complex details and high precision in image classification. We loaded the VGG16 model into our code, excluding fully connected layers, and created a custom Sequential model by adding the VGG16 base. We stacked different layers to fulfill specific functions, such as feature extraction, flattening, dense connections, dropout for regularization, and a final dense layer with a sigmoid activation function for classification.
Training: The number of epochs for training was set to 100.
Evaluation: The final step involved evaluating our model on a set of test images not used during training. Evaluation metrics included accuracy (we achieved 96.89% after 100 epochs) and ROC (Receiver Operating Characteristic) curve analysis, which showed high performance with a curve close to the upper-left corner (0.87 true positive rate).
